#!/usr/bin/env node
/**
 * enhanced_agent_generator.mjs
 *
 * Enhanced Agent Creation Engine with Validation Optimization
 *
 * Key Improvements:
 * - Entropy-aware generation (targets minimum 0.55+)
 * - Optimized branch complexity for validation success
 * - Concept diversity and relevance scoring
 * - Real-time validation simulation during generation
 * - Quality-driven optimization passes
 */

import fs from 'fs';
import path from 'path';
import crypto from 'crypto';
import { fileURLToPath } from 'url';
import { DSLParser } from './copilot-agent-runtime/dslParser.js';
import { ScrollDNAParser } from './copilot-agent-runtime/scrollDNAParser.js';

const ROOT = path.resolve(process.cwd(), '..', '..');
const RUNTIME_ROOT = process.cwd();
const AGENTS_DIR = path.join(RUNTIME_ROOT, 'agents');
const LOGS_DIR = path.join(ROOT, 'standalone', 'logs');
const DASHBOARD_JSON = path.join(ROOT, 'standalone', 'agent-dashboard', 'dashboard.json');

class ValidationSimulator {
  static calculateEntropy(text) {
    const tokens = text.toLowerCase().split(/[^a-z0-9]+/).filter(Boolean);
    const freq = {};
    tokens.forEach(t => freq[t] = (freq[t] || 0) + 1);

    let entropy = 0;
    for (const count of Object.values(freq)) {
      const p = count / tokens.length;
      entropy -= p * Math.log2(p);
    }
    return entropy;
  }

  static calculateBranchCount(branches) {
    return branches.length;
  }

  static calculateSemanticCoherence(branches, concepts) {
    // Measure how well concepts are reflected in branch content
    const branchText = branches.map(b => b.content).join(' ').toLowerCase();
    let coherenceScore = 0;

    for (const concept of concepts) {
      const conceptWords = concept.toLowerCase().split(/[-\s]+/);
      const matches = conceptWords.filter(word => branchText.includes(word)).length;
      coherenceScore += matches / conceptWords.length;
    }

    return coherenceScore / concepts.length; // Normalized 0-1
  }

  static calculateExecutionFeasibility(branches) {
    // Analyze branches for practical execution indicators
    let feasibilityScore = 0;
    const feasibilityIndicators = [
      'validate', 'monitor', 'execute', 'perform', 'implement',
      'establish', 'ensure', 'coordinate', 'generate', 'produce'
    ];

    for (const branch of branches) {
      const content = branch.content.toLowerCase();
      const matches = feasibilityIndicators.filter(indicator => content.includes(indicator)).length;
      feasibilityScore += Math.min(matches / 3, 1); // Cap at 1 per branch
    }

    return feasibilityScore / branches.length; // Average per branch
  }

  static estimateResourceEfficiency(branches) {
    // Estimate resource requirements based on branch complexity
    const totalWords = branches.reduce((sum, b) => sum + b.content.split(/\s+/).length, 0);
    const avgComplexity = totalWords / branches.length;

    // Lower complexity = higher efficiency (inverse relationship)
    return Math.max(0, 1 - (avgComplexity - 20) / 50); // Optimal around 20-70 words
  }

  static simulateValidation(branches, concepts, mindmapData = null) {
    const branchText = branches.map(b => b.content).join(' ');
    const entropy = this.calculateEntropy(branchText);
    const branchCount = this.calculateBranchCount(branches);
    const conceptCount = concepts.length;

    // Advanced metrics
    const semanticCoherence = this.calculateSemanticCoherence(branches, concepts);
    const executionFeasibility = this.calculateExecutionFeasibility(branches);
    const resourceEfficiency = this.estimateResourceEfficiency(branches);

    let score = 0;
    let reasons = [];

    // Entropy scoring (0-4 points)
    if (entropy >= 0.6) score += 4;
    else if (entropy >= 0.5) score += 3;
    else if (entropy >= 0.4) score += 2;
    else score += Math.max(0, entropy * 8);

    // Branch count scoring (0-2 points)
    if (branchCount >= 5) score += 2;
    else if (branchCount >= 3) score += 1;

    // Concept count and diversity (0-2 points)
    if (conceptCount >= 4) score += 2;
    else if (conceptCount >= 3) score += 1;

    // Semantic coherence (0-1 point)
    if (semanticCoherence >= 0.7) score += 1;
    else if (semanticCoherence >= 0.5) score += 0.5;

    // Execution feasibility (0-1 point)
    if (executionFeasibility >= 0.6) score += 1;
    else if (executionFeasibility >= 0.4) score += 0.5;

    // Resource efficiency (0-1 point)
    if (resourceEfficiency >= 0.7) score += 1;
    else if (resourceEfficiency >= 0.5) score += 0.5;

    // Mindmap integration bonus (0-1 point)
    if (mindmapData) {
      const mindmapScore = this.evaluateMindmapIntegration(branches, concepts, mindmapData);
      score += mindmapScore;
    }

    // Fail reasons
    if (entropy < 0.5) reasons.push(`low_entropy(${entropy.toFixed(3)} < 0.5)`);
    if (branchCount < 3) reasons.push(`shallow_branches(${branchCount} < 3)`);
    if (semanticCoherence < 0.4) reasons.push(`low_semantic_coherence(${semanticCoherence.toFixed(2)} < 0.4)`);
    if (executionFeasibility < 0.3) reasons.push(`low_execution_feasibility(${executionFeasibility.toFixed(2)} < 0.3)`);

    return {
      entropy: entropy,
      branchCount: branchCount,
      conceptCount: conceptCount,
      semanticCoherence: semanticCoherence,
      executionFeasibility: executionFeasibility,
      resourceEfficiency: resourceEfficiency,
      score: Math.min(score, 12), // Cap at 12
      maxScore: 12,
      pass: reasons.length === 0,
      reasons: reasons,
      grade: score >= 9 ? 'High' : score >= 6 ? 'Medium' : 'Low'
    };
  }

  static evaluateMindmapIntegration(branches, concepts, mindmapData) {
    // Evaluate how well the agent integrates with mindmap structure
    let integrationScore = 0;

    try {
      // Parse mindmap data if it's a string
      const mindmap = typeof mindmapData === 'string' ? JSON.parse(mindmapData) : mindmapData;

      // Check concept alignment with mindmap traits
      if (mindmap.traits) {
        const traitKeys = Object.keys(mindmap.traits);
        const conceptMatches = concepts.filter(c =>
          traitKeys.some(t => c.toLowerCase().includes(t.toLowerCase()))
        ).length;
        integrationScore += (conceptMatches / concepts.length) * 0.5;
      }

      // Check branch compatibility with execution patterns
      if (mindmap.biometrics && mindmap.biometrics.executionPattern) {
        const pattern = mindmap.biometrics.executionPattern.toLowerCase();
        const branchMatches = branches.filter(b =>
          b.content.toLowerCase().includes(pattern) ||
          pattern.includes(b.content.toLowerCase().split(' ')[0])
        ).length;
        integrationScore += (branchMatches / branches.length) * 0.5;
      }
    } catch (error) {
      // If parsing fails, no bonus
      console.warn('Mindmap integration evaluation failed:', error.message);
    }

    return integrationScore;
  }
}

class EntropyOptimizer {
  static optimizeBranchContent(content, targetEntropy = 0.6) {
    let optimized = content;

    // Add complexity through conditional logic
    const conditions = [
      ' validate preconditions first',
      ' with timeout protection',
      ' using circuit breaker pattern',
      ' after acquiring necessary locks',
      ' with comprehensive error handling'
    ];

    // Add measurement/metrics
    const metrics = [
      ' capture performance metrics',
      ' log operation details',
      ' emit structured telemetry',
      ' record resource utilization'
    ];

    // Add verification/validation
    const verifications = [
      ' verify outcome against acceptance criteria',
      ' assert system invariants hold',
      ' validate against service level objectives',
      ' confirm no regressions detected'
    ];

    // Inject complexity randomly but intelligently
    if (Math.random() > 0.7) {
      const condition = conditions[Math.floor(Math.random() * conditions.length)];
      optimized = optimized.replace(/^(execute|perform|run|apply)/i, `$1${condition}`);
    }

    if (Math.random() > 0.6) {
      const metric = metrics[Math.floor(Math.random() * metrics.length)];
      optimized += ` and ${metric}`;
    }

    if (!/verify|assert|validate|confirm/i.test(content) && Math.random() > 0.5) {
      const verification = verifications[Math.floor(Math.random() * verifications.length)];
      optimized += `. ${verification}`;
    }

    return optimized;
  }

  static diversifyConcepts(category, baseConcepts) {
    const conceptBanks = {
      troubleshooting: [
        'incidents', 'observability', 'anomaly-detection', 'root-cause-analysis',
        'service-reliability', 'incident-response', 'failure-analysis'
      ],
      diagnostics: [
        'telemetry-systems', 'metric-analysis', 'performance-profiling',
        'system-health-monitoring', 'diagnostic-tools', 'benchmarking'
      ],
      evolving: [
        'adaptive-systems', 'real-time-tuning', 'feedback-loops',
        'policy-optimization', 'dynamic-configuration', 'self-healing'
      ],
      error_handling: [
        'fault-tolerance', 'recovery-mechanisms', 'graceful-degradation',
        'error-classification', 'retry-strategies', 'fallback-systems'
      ],
      optimization: [
        'performance-tuning', 'resource-optimization', 'caching-strategies',
        'hotspot-analysis', 'throughput-optimization', 'latency-reduction'
      ],
      integration: [
        'api-contracts', 'data-validation', 'schema-evolution',
        'compatibility-testing', 'interoperability', 'standards-compliance'
      ]
    };

    const bank = conceptBanks[category] || [];
    const additional = bank.filter(c => !baseConcepts.includes(c));

    // Add 1-3 diverse concepts
    const toAdd = [];
    while (toAdd.length < 2 && additional.length > 0) {
      const idx = Math.floor(Math.random() * additional.length);
      toAdd.push(additional.splice(idx, 1)[0]);
    }

    return [...baseConcepts, ...toAdd];
  }
}

class AdaptiveLearning {
  constructor() {
    this.learningHistory = this.loadLearningHistory();
    this.patterns = {
      successfulCategories: {},
      conceptCombinations: {},
      branchPatterns: {},
      validationThresholds: {}
    };
    this.updatePatterns();
  }

  loadLearningHistory() {
    try {
      const historyPath = path.join(RUNTIME_ROOT, 'adaptive_learning_history.json');
      if (fs.existsSync(historyPath)) {
        return JSON.parse(fs.readFileSync(historyPath, 'utf8'));
      }
    } catch (error) {
      console.warn('Could not load learning history:', error.message);
    }
    return { generations: [], patterns: {} };
  }

  updatePatterns() {
    const history = this.learningHistory.generations || [];
    if (history.length === 0) return;

    // Analyze successful patterns
    const successful = history.filter(g => g.accepted);

    // Category success rates
    successful.forEach(g => {
      this.patterns.successfulCategories[g.category] = (this.patterns.successfulCategories[g.category] || 0) + 1;
    });

    // Concept combinations that work well
    successful.forEach(g => {
      const conceptKey = g.concepts.sort().join('|');
      this.patterns.conceptCombinations[conceptKey] = (this.patterns.conceptCombinations[conceptKey] || 0) + 1;
    });

    // Branch pattern analysis
    successful.forEach(g => {
      g.branches.forEach(branch => {
        const words = branch.content.toLowerCase().split(/\s+/);
        const pattern = words.slice(0, 3).join(' '); // First 3 words as pattern
        this.patterns.branchPatterns[pattern] = (this.patterns.branchPatterns[pattern] || 0) + 1;
      });
    });

    // Dynamic validation thresholds based on history
    if (successful.length > 5) {
      const avgScore = successful.reduce((sum, g) => sum + g.validationScore.score, 0) / successful.length;
      const avgEntropy = successful.reduce((sum, g) => sum + g.validationScore.entropy, 0) / successful.length;
      this.patterns.validationThresholds = {
        minScore: Math.max(6, avgScore * 0.8),
        minEntropy: Math.max(0.4, avgEntropy * 0.9)
      };
    }
  }

  getCategoryRecommendation() {
    const categories = Object.keys(this.patterns.successfulCategories);
    if (categories.length === 0) return null;

    // Weight by success rate but add exploration
    const total = Object.values(this.patterns.successfulCategories).reduce((a, b) => a + b, 0);
    const weights = categories.map(cat => this.patterns.successfulCategories[cat] / total);

    // Add exploration factor (10% chance of random)
    if (Math.random() < 0.1) {
      return categories[Math.floor(Math.random() * categories.length)];
    }

    // Weighted selection
    const rand = Math.random();
    let cumulative = 0;
    for (let i = 0; i < categories.length; i++) {
      cumulative += weights[i];
      if (rand <= cumulative) return categories[i];
    }
    return categories[0];
  }

  getConceptSuggestions(category, baseConcepts) {
    const suggestions = [];
    const combinations = Object.entries(this.patterns.conceptCombinations)
      .filter(([key, count]) => count > 1 && key.includes(category))
      .sort(([,a], [,b]) => b - a)
      .slice(0, 3);

    combinations.forEach(([key]) => {
      const concepts = key.split('|');
      concepts.forEach(concept => {
        if (!baseConcepts.includes(concept) && !suggestions.includes(concept)) {
          suggestions.push(concept);
        }
      });
    });

    return suggestions.slice(0, 2); // Max 2 suggestions
  }

  getBranchPatternSuggestions() {
    return Object.entries(this.patterns.branchPatterns)
      .filter(([, count]) => count > 2)
      .sort(([,a], [,b]) => b - a)
      .slice(0, 5)
      .map(([pattern]) => pattern);
  }

  recordGeneration(candidate, accepted, reason = null) {
    const record = {
      timestamp: new Date().toISOString(),
      category: candidate.category,
      concepts: candidate.concepts,
      branches: candidate.branches.map(b => ({ content: b.content })),
      validationScore: candidate.validationScore,
      accepted,
      reason
    };

    this.learningHistory.generations.push(record);

    // Keep only last 100 generations
    if (this.learningHistory.generations.length > 100) {
      this.learningHistory.generations = this.learningHistory.generations.slice(-100);
    }

    // Save to disk
    try {
      const historyPath = path.join(RUNTIME_ROOT, 'adaptive_learning_history.json');
      fs.writeFileSync(historyPath, JSON.stringify(this.learningHistory, null, 2));
    } catch (error) {
      console.warn('Could not save learning history:', error.message);
    }

    // Update patterns if accepted
    if (accepted) {
      this.updatePatterns();
    }
  }

  getDynamicThresholds() {
    return this.patterns.validationThresholds;
  }
}

class MultiObjectiveOptimizer {
  static optimize(agentCandidate, mindmapData = null, learning = null) {
    const { branches, concepts, category } = agentCandidate;
    let bestCandidate = { branches: [...branches], concepts: [...concepts] };
    let bestFitness = this.calculateFitness(bestCandidate, mindmapData, learning);

    // Multi-objective optimization with Pareto front
    for (let iteration = 0; iteration < 10; iteration++) {
      const candidates = this.generateVariations(bestCandidate, category, mindmapData, learning);

      for (const candidate of candidates) {
        const fitness = this.calculateFitness(candidate, mindmapData, learning);
        if (this.dominates(fitness, bestFitness)) {
          bestCandidate = candidate;
          bestFitness = fitness;
        }
      }
    }

    return bestCandidate;
  }

  static calculateFitness(candidate, mindmapData, learning) {
    const validation = ValidationSimulator.simulateValidation(candidate.branches, candidate.concepts, mindmapData);

    // Multi-objective fitness: [validation_score, entropy, semantic_coherence, execution_feasibility, resource_efficiency]
    const objectives = [
      validation.score / validation.maxScore, // Normalized score
      validation.entropy / 1.0, // Max entropy ~1.0
      validation.semanticCoherence,
      validation.executionFeasibility,
      validation.resourceEfficiency
    ];

    // Learning bonus
    let learningBonus = 0;
    if (learning) {
      const thresholds = learning.getDynamicThresholds();
      if (thresholds.minScore && validation.score >= thresholds.minScore) learningBonus += 0.1;
      if (thresholds.minEntropy && validation.entropy >= thresholds.minEntropy) learningBonus += 0.1;
    }

    return {
      objectives,
      overall: objectives.reduce((a, b) => a + b, 0) / objectives.length + learningBonus,
      validation
    };
  }

  static dominates(fitnessA, fitnessB) {
    // Pareto dominance: A dominates B if A is better in at least one objective
    // and not worse in any other
    const aBetter = fitnessA.objectives.some((a, i) => a > fitnessB.objectives[i]);
    const bNotBetter = fitnessA.objectives.every((a, i) => a >= fitnessB.objectives[i]);

    return aBetter && bNotBetter;
  }

  static generateVariations(baseCandidate, category, mindmapData, learning) {
    const variations = [];

    // Branch variations
    for (let i = 0; i < 3; i++) {
      const newBranches = baseCandidate.branches.map(branch => ({
        ...branch,
        content: EntropyOptimizer.optimizeBranchContent(branch.content)
      }));

      // Add learning-based branch patterns
      if (learning && Math.random() > 0.7) {
        const patterns = learning.getBranchPatternSuggestions();
        if (patterns.length > 0) {
          const pattern = patterns[Math.floor(Math.random() * patterns.length)];
          const randomBranch = newBranches[Math.floor(Math.random() * newBranches.length)];
          randomBranch.content = pattern + ' ' + randomBranch.content.split(' ').slice(3).join(' ');
        }
      }

      variations.push({
        branches: newBranches,
        concepts: [...baseCandidate.concepts]
      });
    }

    // Concept variations
    for (let i = 0; i < 2; i++) {
      let newConcepts = EntropyOptimizer.diversifyConcepts(category, baseCandidate.concepts);

      // Add learning-based concept suggestions
      if (learning && Math.random() > 0.6) {
        const suggestions = learning.getConceptSuggestions(category, newConcepts);
        newConcepts = [...newConcepts, ...suggestions];
      }

      variations.push({
        branches: [...baseCandidate.branches],
        concepts: newConcepts
      });
    }

    return variations;
  }
}

class EnhancedGenerator {
  constructor() {
    this.existingAgents = this.loadExistingAgents();
    this.adaptiveLearning = new AdaptiveLearning();
    this.generationStats = {
      attempts: 0,
      accepted: 0,
      rejected: [],
      entropyDistribution: [],
      scoreDistribution: []
    };
  }

  loadExistingAgents() {
    const agents = [];
    try {
      const dashboardPath = path.join(ROOT, 'standalone', 'agent-dashboard', 'dashboard.json');
      if (fs.existsSync(dashboardPath)) {
        const dashboard = JSON.parse(fs.readFileSync(dashboardPath, 'utf8'));
        if (dashboard.agents) {
          agents.push(...dashboard.agents.map(a => ({
            file: `${a.file}`,
            concepts: new Set(a.concepts.map(c => c.toLowerCase())),
            runtimeId: a.runtime_id
          })));
        }
      }
    } catch (error) {
      console.warn('Could not load existing agents:', error.message);
    }
    return agents;
  }

  shortHash(n = 6) {
    return crypto.randomBytes(4).toString('hex').slice(0, n);
  }

  toTitleCase(idPart) {
    return idPart.replace(/[_-]+/g, ' ').replace(/\b\w/g, (m) => m.toUpperCase());
  }

  optimizeForValidation(branches, concepts, category, maxIterations = 5) {
    let bestBranches = [...branches];
    let bestConcepts = [...concepts];
    let bestScore = ValidationSimulator.simulateValidation(branches, concepts);

    for (let i = 0; i < maxIterations; i++) {
      // Create variation
      const newBranches = bestBranches.map(b => ({
        ...b,
        content: EntropyOptimizer.optimizeBranchContent(b.content)
      }));
      const newConcepts = EntropyOptimizer.diversifyConcepts(category, bestConcepts);

      const newScore = ValidationSimulator.simulateValidation(newBranches, newConcepts);

      // Keep better variation
      if (newScore.score > bestScore.score || (newScore.score === bestScore.score && newScore.entropy > bestScore.entropy)) {
        bestBranches = newBranches;
        bestConcepts = newConcepts;
        bestScore = newScore;
      }
    }

    return { branches: bestBranches, concepts: bestConcepts, score: bestScore };
  }

  buildEnhancedBranches(category) {
    const templates = this.getCategoryTemplates(category);

    // Start with 4-6 branches for better entropy
    const count = 4 + Math.floor(Math.random() * 3); // 4-6
    const shuffled = [...templates].sort(() => Math.random() - 0.5);
    const selected = shuffled.slice(0, count);

    return selected.map((content, index) => {
      const optimizedContent = EntropyOptimizer.optimizeBranchContent(content);
      return {
        id: `${this.shortHash(8)}_branch_${index + 1}`,
        content: optimizedContent
      };
    });
  }

  getCategoryTemplates(category) {
    const templates = {
      troubleshooting: [
        'Conduct systematic failure analysis and isolate root cause',
        'Implement targeted intervention with comprehensive monitoring',
        'Establish performance baselines and validate system behavior',
        'Orchestrate remediation workflow with automated verification',
        'Ensure service resilience through proactive health monitoring',
        'Coordinate incident response with stakeholder communication',
        'Validate recovery procedures and prevent recurrence patterns'
      ],
      diagnostics: [
        'Aggregate multi-dimensional telemetry data across system boundaries',
        'Execute comparative analysis against established performance benchmarks',
        'Map dependency relationships and identify critical path constraints',
        'Generate actionable insights through statistical anomaly detection',
        'Cross-reference incident patterns with system configuration changes',
        'Produce diagnostic reports with prioritized remediation recommendations',
        'Validate diagnostic accuracy through controlled testing scenarios'
      ],
      evolving: [
        'Continuously evaluate system performance metrics and environmental factors',
        'Dynamically adjust operational parameters based on real-time feedback loops',
        'Optimize resource allocation through predictive analytics and trend analysis',
        'Implement adaptive strategies with controlled experimentation frameworks',
        'Refine decision policies through reinforcement learning algorithms',
        'Scale operational capacity in response to demand pattern variations',
        'Persist successful configuration changes across deployment environments'
      ],
      error_handling: [
        'Implement comprehensive error classification and categorization system',
        'Execute graduated retry strategies with exponential backoff algorithms',
        'Activate alternative execution paths when primary workflows fail',
        'Generate structured error telemetry for system observability',
        'Enforce transactional consistency during error recovery operations',
        'Provide user-transparent fallback mechanisms for degraded operations',
        'Maintain audit trails for all error handling and recovery actions'
      ],
      optimization: [
        'Perform comprehensive performance profiling and bottleneck identification',
        'Implement multi-layered caching strategies for resource optimization',
        'Execute algorithmic improvements with measurable efficiency gains',
        'Optimize database query patterns and data access methodologies',
        'Streamline computational workflows through parallel processing techniques',
        'Minimize resource overhead through intelligent scheduling algorithms',
        'Validate performance improvements against established service objectives'
      ],
      integration: [
        'Establish secure communication channels with external service dependencies',
        'Implement comprehensive data validation and schema compliance checking',
        'Orchestrate distributed transactions with consistency guarantees',
        'Monitor service level agreements and enforce contractual obligations',
        'Handle graceful degradation scenarios during partial system failures',
        'Implement circuit breaker patterns to prevent cascading failures',
        'Generate comprehensive integration testing and validation reports'
      ]
    };

    return templates[category] || templates.troubleshooting;
  }

  buildEnhancedConcepts(category) {
    const conceptBanks = {
      troubleshooting: ['troubleshooting', 'system-observability', 'incident-response', 'failure-analysis', 'root-cause-analysis'],
      diagnostics: ['system-diagnostics', 'telemetry-analysis', 'performance-monitoring', 'anomaly-detection', 'health-checks'],
      evolving: ['adaptive-systems', 'real-time-tuning', 'policy-optimization', 'feedback-loops', 'dynamic-configuration'],
      error_handling: ['fault-tolerance', 'error-recovery', 'retry-mechanisms', 'circuit-breakers', 'graceful-degradation'],
      optimization: ['performance-tuning', 'resource-optimization', 'algorithm-improvement', 'caching-strategies'],
      integration: ['system-integration', 'api-contracts', 'data-validation', 'service-composition', 'interoperability']
    };

    const base = conceptBanks[category] || conceptBanks.troubleshooting;
    return EntropyOptimizer.diversifyConcepts(category, base.slice(0, 3));
  }

  jaccardSimilarity(setA, setB) {
    const intersection = new Set([...setA].filter(x => setB.has(x)));
    const union = new Set([...setA, ...setB]);
    return union.size === 0 ? 0 : intersection.size / union.size;
  }

  conceptOverlap(candidateConcepts, existingConcepts) {
    const candidateSet = new Set(candidateConcepts.map(c => c.toLowerCase()));
    const existingSet = new Set(existingConcepts);
    const intersection = new Set([...candidateSet].filter(x => existingSet.has(x)));
    return candidateSet.size === 0 ? 0 : intersection.size / candidateSet.size;
  }

  checkSimilarityGuard(candidate) {
    const branchText = candidate.branches.map(b => b.content).join(' ');
    const candidateTokens = new Set(branchText.toLowerCase().split(/[^a-z0-9]+/).filter(Boolean));

    for (const existing of this.existingAgents) {
      // Skip if same runtime ID
      if (existing.runtimeId === candidate.runtimeId) continue;

      // Jaccard similarity check (branches)
      if (candidateTokens.size > 0) {
        // Note: We don't have existing tokens stored, so we'll rely on concept overlap for now
      }

      // Concept overlap check
      const overlap = this.conceptOverlap(candidate.concepts, existing.concepts);
      if (overlap >= 0.50) { // Lower threshold for similarity
        return {
          ok: false,
          reason: `High concept overlap (${(overlap * 100).toFixed(0)}%) with existing agent ${existing.runtimeId}`
        };
      }
    }

    return { ok: true };
  }

  generateOptimizedAgent(category = null, targetSource = 'optimized.json', mindmapData = null) {
    this.generationStats.attempts++;

    // Use adaptive learning to recommend category if not specified
    const selectedCategory = category || this.adaptiveLearning.getCategoryRecommendation() || 'troubleshooting';

    // Generate base agent
    const runtimeId = `enhanced_${selectedCategory}_${this.shortHash(8)}`;
    const title = this.toTitleCase(runtimeId.replace('enhanced_', ''));
    const source = targetSource;

    // Build enhanced branches and concepts with learning insights
    let branches = this.buildEnhancedBranches(selectedCategory);
    let concepts = this.buildEnhancedConcepts(selectedCategory);

    // Apply learning-based enhancements
    const learningSuggestions = this.adaptiveLearning.getConceptSuggestions(selectedCategory, concepts);
    if (learningSuggestions.length > 0) {
      concepts = [...concepts, ...learningSuggestions];
    }

    // Multi-objective optimization
    const optimizedCandidate = MultiObjectiveOptimizer.optimize(
      { branches, concepts, category: selectedCategory },
      mindmapData,
      this.adaptiveLearning
    );

    // Final validation with all enhancements
    const validationScore = ValidationSimulator.simulateValidation(
      optimizedCandidate.branches,
      optimizedCandidate.concepts,
      mindmapData
    );

    const candidate = {
      runtimeId,
      title,
      source,
      branches: optimizedCandidate.branches,
      concepts: optimizedCandidate.concepts,
      category: selectedCategory,
      validationScore
    };

    // Record generation for learning
    const accepted = this.evaluateAcceptance(candidate);
    this.adaptiveLearning.recordGeneration(candidate, accepted);

    if (!accepted) {
      const reason = this.getRejectionReason(candidate);
      return { accepted: false, candidate, reason };
    }

    // File uniqueness check
    const outFile = path.join(AGENTS_DIR, `${runtimeId}_Agent.ts`);
    if (fs.existsSync(outFile)) {
      return { accepted: false, candidate, reason: 'Agent file already exists' };
    }

    this.generationStats.accepted++;
    this.generationStats.entropyDistribution.push(validationScore.entropy);
    this.generationStats.scoreDistribution.push(validationScore.score);

    return {
      accepted: true,
      candidate,
      outFile,
      tsCode: this.scaffoldAgentTS(candidate)
    };
  }

  evaluateAcceptance(candidate) {
    // Check dynamic thresholds from learning
    const dynamicThresholds = this.adaptiveLearning.getDynamicThresholds();
    const scoreThreshold = dynamicThresholds.minScore || 6;
    const entropyThreshold = dynamicThresholds.minEntropy || 0.4;

    // Basic validation checks
    if (candidate.validationScore.score < scoreThreshold) return false;
    if (candidate.validationScore.entropy < entropyThreshold) return false;
    if (candidate.validationScore.branchCount < 3) return false;

    // Similarity guard
    const similarityCheck = this.checkSimilarityGuard(candidate);
    if (!similarityCheck.ok) return false;

    return true;
  }

  getRejectionReason(candidate) {
    const dynamicThresholds = this.adaptiveLearning.getDynamicThresholds();
    const scoreThreshold = dynamicThresholds.minScore || 6;
    const entropyThreshold = dynamicThresholds.minEntropy || 0.4;

    if (candidate.validationScore.score < scoreThreshold) {
      return `Validation score too low (${candidate.validationScore.score} < ${scoreThreshold})`;
    }
    if (candidate.validationScore.entropy < entropyThreshold) {
      return `Entropy too low (${candidate.validationScore.entropy.toFixed(3)} < ${entropyThreshold})`;
    }
    if (candidate.validationScore.branchCount < 3) {
      return `Insufficient branches (${candidate.validationScore.branchCount} < 3)`;
    }

    const similarityCheck = this.checkSimilarityGuard(candidate);
    if (!similarityCheck.ok) return similarityCheck.reason;

    return 'Unknown rejection reason';
  }

  scaffoldAgentTS(candidate) {
    const { runtimeId, title, source, branches, concepts } = candidate;

    return `import SmartPayloadBuilder from '../utils';
import { AgentExecutor } from '../types';

const RUNTIME_ID = '${runtimeId}';
const TITLE = '${title}';
const SOURCE = '${source}';

const ${runtimeId}_Agent: AgentExecutor = {
  execute: async (payload) => {
    try {
      const output = {
        runtime_id: RUNTIME_ID,
        title: TITLE,
        timestamp: new Date().toISOString().replace(/:/g, '-'),
        source: SOURCE,
        branches: ${JSON.stringify(branches, null, 2)},
        concepts: ${JSON.stringify(concepts, null, 2)},
        validation_profile: {
          entropy_score: ${candidate.validationScore.entropy.toFixed(3)},
          branch_count: ${candidate.validationScore.branchCount},
          concept_count: ${candidate.validationScore.conceptCount},
          quality_score: ${candidate.validationScore.score},
          signal_grade: '${candidate.validationScore.grade}'
        }
      };

      return SmartPayloadBuilder.success('Enhanced agent executed successfully', output);
    } catch (error: any) {
      return SmartPayloadBuilder.error(\`\${RUNTIME_ID}_Agent Error\`, (error as any)?.message ?? String(error));
    }
  }
};

export default ${runtimeId}_Agent;
`;
  }

  generateBatch(targetAgents = 5, mindmapData = null) {
    const results = [];
    const accepted = [];

    console.log(`ðŸŽ¯ Generating ${targetAgents} enhanced agents with adaptive learning and multi-objective optimization...`);
    console.log(`ðŸ§  Adaptive Learning: ${Object.keys(this.adaptiveLearning.patterns.successfulCategories).length} learned patterns`);

    // Show current learning insights
    const recommendedCategory = this.adaptiveLearning.getCategoryRecommendation();
    if (recommendedCategory) {
      console.log(`ðŸ“ˆ Recommended category: ${recommendedCategory} (based on success history)`);
    }

    for (let i = 0; i < targetAgents; i++) {
      const source = `enhanced_generation_${new Date().toISOString().split('T')[0]}.json`;

      const result = this.generateOptimizedAgent(null, source, mindmapData); // Let adaptive learning choose category
      results.push(result);

      if (result.accepted) {
        accepted.push(result);
        // Write the file
        fs.writeFileSync(result.outFile, result.tsCode, 'utf8');
        console.log(`âœ… Generated: ${result.candidate.runtimeId} (${result.candidate.category})`);
        console.log(`   ðŸ“Š Score: ${result.candidate.validationScore.score}/12, Entropy: ${result.candidate.validationScore.entropy.toFixed(3)}, Grade: ${result.candidate.validationScore.grade}`);
      } else {
        console.log(`âŒ Rejected: ${result.candidate.runtimeId} - ${result.reason}`);
        this.generationStats.rejected.push(result);
      }
    }

    return { results, accepted };
  }

  printStats() {
    const stats = this.generationStats;
    console.log('\nðŸ“Š Enhanced Generation Statistics');
    console.log('====================================');
    console.log(`Total attempts: ${stats.attempts}`);
    console.log(`Accepted: ${stats.accepted}`);
    console.log(`Rejected: ${stats.rejected.length}`);
    console.log(`Success rate: ${((stats.accepted / stats.attempts) * 100).toFixed(1)}%`);

    if (stats.entropyDistribution.length > 0) {
      const avgEntropy = stats.entropyDistribution.reduce((a, b) => a + b, 0) / stats.entropyDistribution.length;
      const avgScore = stats.scoreDistribution.reduce((a, b) => a + b, 0) / stats.scoreDistribution.length;

      console.log('\nValidation Metrics:');
      console.log(`Average entropy: ${avgEntropy.toFixed(3)}`);
      console.log(`Average validation score: ${avgScore.toFixed(1)}/12`);
      console.log(`Entropy target (>=0.5): ${stats.entropyDistribution.filter(e => e >= 0.5).length}/${stats.entropyDistribution.length} passed`);

      // Show adaptive learning insights
      const thresholds = this.adaptiveLearning.getDynamicThresholds();
      if (Object.keys(thresholds).length > 0) {
        console.log('\nðŸ§  Adaptive Learning Thresholds:');
        console.log(`Dynamic min score: ${thresholds.minScore || 'N/A'}`);
        console.log(`Dynamic min entropy: ${thresholds.minEntropy || 'N/A'}`);
      }

      const successfulCats = Object.entries(this.adaptiveLearning.patterns.successfulCategories)
        .sort(([,a], [,b]) => b - a)
        .slice(0, 3);
      if (successfulCats.length > 0) {
        console.log('\nðŸ“ˆ Top Performing Categories:');
        successfulCats.forEach(([cat, count]) => {
          console.log(`  ${cat}: ${count} successes`);
        });
      }
    }
  }
}

// Main execution
function main() {
  const generator = new EnhancedGenerator();

  // Ensure agents directory exists
  fs.mkdirSync(AGENTS_DIR, { recursive: true });

  // Generate batch of enhanced agents
  const { accepted } = generator.generateBatch(5); // Generate 5 enhanced agents

  // Print statistics
  generator.printStats();

  // Save generation log
  const logPath = path.join(RUNTIME_ROOT, 'enhanced_generation_log.txt');
  const logContent = [
    `Enhanced Agent Generation - ${new Date().toISOString()}`,
    '================================================',
    `Generated: ${accepted.length} agents`,
    '',
    'Accepted Agents:',
    ...accepted.map(a => `- ${a.candidate.runtimeId} (${a.candidate.category}) - Score: ${a.candidate.validationScore.score}/12, Grade: ${a.candidate.validationScore.grade}`),
    '',
    'Validation Statistics:',
    `- Average Entropy: ${(accepted.reduce((sum, a) => sum + a.candidate.validationScore.entropy, 0) / accepted.length).toFixed(3)}`,
    `- Average Score: ${(accepted.reduce((sum, a) => sum + a.candidate.validationScore.score, 0) / accepted.length).toFixed(1)}/12`,
    `- All agents should pass validation thresholds (>=0.5 entropy, >=3 branches)`,
    '',
    'Adaptive Learning Insights:',
    `- Learned patterns: ${Object.keys(generator.adaptiveLearning.patterns.successfulCategories).length} categories`,
    `- Dynamic thresholds: ${JSON.stringify(generator.adaptiveLearning.getDynamicThresholds())}`,
    '',
    'To test validation: cd ../.. && npm run validate-agents'
  ].join('\n');

  fs.writeFileSync(logPath, logContent, 'utf8');
  console.log(`\nðŸ“„ Enhanced generation log saved: ${logPath}`);
}

const __FILENAME = fileURLToPath(import.meta.url);
const isMain = process.argv[1] && path.resolve(process.argv[1]) === __FILENAME;
if (isMain) {
  main();
}

export default EnhancedGenerator;
